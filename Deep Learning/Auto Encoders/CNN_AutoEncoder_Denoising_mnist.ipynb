{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_Autoencoder_Denoising_MNIST.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYK7dFqL/XYAPwKVq196nu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"q28IKljuqYBo","colab_type":"text"},"source":["# Autoencoder denoising\n","\n","Example of Autoencoder Convolutional Neural Net (CNN) with TensorFlow (TF) 2.0 for denoising. This example builds an Autoencoder from scratch, with custom layers and training.\n","\n","Sources:\n","\n","*   [MIT - Introduction to Deep Learning](http://introtodeeplearning.com)\n","*   [PyImageSearch](https://www.pyimagesearch.com/2020/02/24/denoising-autoencoders-with-keras-tensorflow-and-deep-learning/)\n","\n","\n","`Author: Rodrigo Vimieiro`\n","\n","`Date: Apr, 2020`"]},{"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/LAVI-USP/Machine-Learning/blob/master/Deep%20Learning/Auto%20Encoders/CNN_AutoEncoder_Denoising_mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/LAVI-USP/Machine-Learning/blob/master/Deep%20Learning/Auto%20Encoders/CNN_AutoEncoder_Denoising_mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"7By_UTUOTOZK","colab_type":"code","colab":{}},"source":["# Import Tensorflow 2.0\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import functools\n","\n","from tqdm import tqdm\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RBRnvLj0qjJS","colab_type":"text"},"source":["## Define MNIST help functions:"]},{"cell_type":"code","metadata":{"id":"4piRRA4a3e0H","colab_type":"code","colab":{}},"source":["class MNIST_Helper():\n","    \n","  def download(self):\n","\n","    # Loads the MNIST dataset.\n","    (self.x_train, self.y_train) ,(self.x_test, self.y_test) =  tf.keras.datasets.mnist.load_data()\n","\n","    self.train_dataset_shape = self.x_train.shape\n","    self.test_dataset_shape = self.x_test.shape\n","\n","\n","  def print_information(self):\n","\n","    # Print informations about the MNIST dataset.\n","    print(\"There is %d training samples, containing images with shape of: %dx%d and %d channel\" \n","          % (self.train_dataset_shape[0],self.train_dataset_shape[1],self.train_dataset_shape[2],self.train_dataset_shape[3]))\n","    print(\"Train variable shape:\", end='')\n","    print(self.train_dataset_shape)\n","\n","  def pre_process(self):\n","\n","    # Reshape to have 1 channel (last dimension) and normalize\n","    self.x_train = np.expand_dims(self.x_train, axis=-1).astype(np.float32)\n","    self.x_test = np.expand_dims(self.x_test, axis=-1).astype(np.float32)\n","\n","    # Normalize data\n","    ## https://stats.stackexchange.com/questions/185853/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn\n","    self.x_train /= 255\n","    self.x_test /= 255\n","\n","    self.train_dataset_shape = self.x_train.shape\n","    self.test_dataset = self.x_test.shape\n","\n","  def noise_injection(self):\n","\n","    # Gaussian noise\n","    self.x_train_noise = self.x_train + tf.random.normal(self.x_train.shape, mean=0.5, stddev=0.5, dtype=np.float32)\n","    self.x_test_noise = self.x_test + tf.random.normal(self.x_test.shape, mean=0.5, stddev=0.5, dtype=np.float32)\n","\n","    # Poisson noise (not really, lambda should be equal to mean)\n","    #self.x_train_noise += tf.random.poisson(self.x_train_noise.shape, lam=60/255, dtype=np.float32)\n","    #self.x_test_noise += tf.random.poisson(self.x_test_noise.shape, lam=60/255, dtype=np.float32)\n","\n","    self.x_train_noise = np.clip(self.x_train_noise, 0, 1)\n","    self.x_test_noise = np.clip(self.x_test_noise, 0, 1)\n","  \n","  def create_dataset_iterable(self):\n","\n","    # Create database objects\n","    self.train_dataset = tf.data.Dataset.from_tensor_slices((self.x_train_noise, self.x_train))\n","    self.test_dataset = tf.data.Dataset.from_tensor_slices((self.x_test_noise, self.x_test))\n","      \n","  def shuffle_dataset(self, dataset_size):\n","    \n","    return self.train_dataset.shuffle(dataset_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MN6kThB7qOIf","colab_type":"text"},"source":["### Defining the Autoencoder model:"]},{"cell_type":"code","metadata":{"id":"S4zIujQpWz4O","colab_type":"code","colab":{}},"source":["class autoencoder_model(tf.keras.Model):\n","\n","  def __init__(self):\n","\n","    super(autoencoder_model, self).__init__()\n","    \n","    self.n_outputs = 30 # Number of latent variables\n","    self.n_filters = 32\n","    self.img_input_shape = (28,28,1) # nRows X nCols X nChannels\n","\n","    self.encoder = self.build_encoder()\n","    self.decoder = self.build_decoder()\n","\n","  def build_encoder(self):\n","\n","    Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='same', activation='relu', strides=2)\n","    BatchNormalization = tf.keras.layers.BatchNormalization\n","    Flatten = tf.keras.layers.Flatten\n","    Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n","\n","    model = tf.keras.Sequential([\n","\n","      # Downscaling convolutions                           \n","      Conv2D(filters=1*self.n_filters, kernel_size=3, input_shape=self.img_input_shape),\n","      BatchNormalization(),\n","      \n","      Conv2D(filters=2*self.n_filters, kernel_size=3),\n","      BatchNormalization(),\n","\n","      Flatten(),\n","      Dense(self.n_outputs, activation=None),\n","\n","    ])\n","    return model\n","\n","  def build_decoder(self):\n","    '''\n","    https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8\n","    https://stackoverflow.com/questions/53654310/what-is-the-difference-between-upsampling2d-and-conv2dtranspose-functions-in-ker\n","    '''\n","\n","    Conv2DTranspose = functools.partial(tf.keras.layers.Conv2DTranspose, padding='same', activation='relu', strides=2)\n","    BatchNormalization = tf.keras.layers.BatchNormalization\n","    Flatten = tf.keras.layers.Flatten\n","    Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n","    Reshape = tf.keras.layers.Reshape\n","\n","    # Build the decoder network using the Sequential API\n","    model = tf.keras.Sequential([\n","\n","      Dense(7*7*2*self.n_filters,input_shape=(self.n_outputs,)),  \n","      Reshape(target_shape=(7, 7, 2*self.n_filters)),\n","\n","      # Upscaling convolutions (inverse of encoder)\n","      Conv2DTranspose(filters=2*self.n_filters, kernel_size=3),\n","      Conv2DTranspose(filters=1*self.n_filters, kernel_size=3),\n","      Conv2DTranspose(filters=1, kernel_size=3, strides=1),\n","    ])\n","\n","    return model\n","\n","  def call(self, x):\n","\n","    latent_space = self.encoder(x)\n","    img_recon = self.decoder(latent_space)\n","\n","    return img_recon"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HI1mCsVdzp05","colab_type":"text"},"source":["### Defining the loss function:"]},{"cell_type":"code","metadata":{"id":"El1rRG_qt7LW","colab_type":"code","colab":{}},"source":["def loss_function(img_recon, img_without_noise):\n","    \n","    loss = tf.math.reduce_mean(tf.square(img_recon - img_without_noise),axis=(1,2))\n","\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EwYZasG3z5ON","colab_type":"text"},"source":["### Defining the optimizer:"]},{"cell_type":"code","metadata":{"id":"68TtypEmxhf4","colab_type":"code","colab":{}},"source":["def create_optimizer(learning_rate):\n","\n","  return tf.keras.optimizers.Adam(learning_rate) # define our optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vZX9yqz3z70Y","colab_type":"text"},"source":["### Defining the trainning step:"]},{"cell_type":"code","metadata":{"id":"7zpqUckavlQf","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(autoencoder, img_with_noise , img_without_noise, optimizer):\n","\n","  with tf.GradientTape() as tape:\n","        \n","    # Feed images into autoencoder\n","    img_recon = autoencoder(img_with_noise)\n","        \n","    # Calc the loss\n","    loss = loss_function(img_recon, img_without_noise)\n","\n","    ### Backpropagation ###\n","    # Get the gradients\n","    grads = tape.gradient(loss, autoencoder.trainable_variables)\n","\n","    # Update the weights\n","    optimizer.apply_gradients(zip(grads, autoencoder.trainable_variables))\n","\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"900D5tSl0BX8","colab_type":"text"},"source":["### Defining the trainning loop:"]},{"cell_type":"code","metadata":{"id":"0c97i7mkyuLl","colab_type":"code","colab":{}},"source":["def train_model(autoencoder, dataset, num_epochs, batch_size, learning_rate):\n","\n","  optimizer = create_optimizer(learning_rate)\n","\n","  train_loss_history = []\n","  validation_loss_history = []\n","\n","  metrics_names = ['train_loss','val_loss'] \n","  \n","  # Loop on each epoch\n","  for epoch in range(num_epochs):\n","\n","    print(\"\\nepoch {}/{}\".format(epoch+1,num_epochs))\n","\n","    progBar = tf.keras.utils.Progbar(MNIST.train_dataset_shape[0], stateful_metrics=metrics_names)\n","\n","    # Loop on each batch of train dataset\n","    for idX, (batch_x, batch_y) in enumerate(MNIST.train_dataset.batch(batch_size)): \n","        \n","      # Train the model\n","      train_loss = train_step(autoencoder, batch_x, batch_y, optimizer)\n","\n","      values=[('train_loss',train_loss)]\n","\n","      progBar.update(idX*batch_size, values=values) \n","\n","      train_loss_history.append(tf.math.reduce_mean(train_loss))\n","\n","\n","    # Loop on each batch of test dataset for validation\n","    for batch_x, batch_y in MNIST.test_dataset.batch(batch_size):\n","\n","      # Foward image through the network\n","      img_recon = autoencoder(batch_x)\n","\n","      # Calc the loss\n","      val_loss = loss_function(img_recon, batch_y)\n","\n","      validation_loss_history.append(tf.math.reduce_mean(val_loss))\n","\n","\n","    # Update progBar with val_loss\n","    values=[('train_loss',train_loss),('val_loss',val_loss)]\n","\n","    progBar.update(MNIST.train_dataset_shape[0], values=values, finalize=True)\n","\n","\n","    # Shuffle train dataset for next epoch\n","    MNIST.train_dataset = MNIST.shuffle_dataset(MNIST.train_dataset_shape[0])\n","  \n","  train_loss = [train_loss_history[x].numpy() for x in range(0,len(train_loss_history),len(train_loss_history)//num_epochs)]\n","  val_loss = [validation_loss_history[x].numpy() for x in range(0,len(validation_loss_history),len(validation_loss_history)//num_epochs)]\n","  \n","  return train_loss, val_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mfKI0RNXYBEO","colab_type":"text"},"source":["-----------------------------------------------------------------------\n","## %% Main code %%"]},{"cell_type":"code","metadata":{"id":"7YwctV1f1qSp","colab_type":"code","colab":{}},"source":["# Create MNIST helper class\n","MNIST = MNIST_Helper()\n","\n","# Download the dataset\n","MNIST.download()\n","\n","# Pre processing\n","MNIST.pre_process()\n","\n","# Display some dataset information\n","MNIST.print_information()\n","\n","# Noise injection\n","MNIST.noise_injection()\n","\n","# Create TF Dataset object \n","MNIST.create_dataset_iterable()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3fDcHP4XTFP","colab_type":"code","colab":{}},"source":["### Examining the MNIST training dataset ###\n","\n","idx_train_img = 24010 #@param {type:\"slider\", min:0, max:59999, step:1}\n","\n","plt.figure(figsize=(5,5))\n","plt.subplot(1, 2, 1)\n","plt.imshow(np.squeeze(MNIST.x_train[idx_train_img]),'gray')\n","plt.title(np.squeeze(MNIST.y_train[idx_train_img])); plt.grid(False)\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(np.squeeze(MNIST.x_train_noise[idx_train_img]),'gray')\n","plt.title(np.squeeze(MNIST.y_train[idx_train_img])); plt.grid(False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvFRBLIvfeXy","colab_type":"code","colab":{}},"source":["autoencoder = autoencoder_model()\n","#autoencoder.encoder.summary()\n","#autoencoder.decoder.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"arpGkI3jXNPZ","colab_type":"code","colab":{}},"source":["# Training hyperparameters\n","num_epochs = 15\n","batch_size = 20\n","learning_rate = 5e-4\n","\n","# Train the model \n","train_loss, val_loss = train_model(autoencoder, MNIST, num_epochs, batch_size, learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMK0l3vOh3uC","colab_type":"code","colab":{}},"source":["# Plot loss results\n","N = np.arange(0, num_epochs)\n","plt.figure()\n","plt.plot(N, train_loss, label=\"train_loss\")\n","plt.plot(N, val_loss, label=\"val_loss\")\n","plt.title(\"Results\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss\")\n","plt.legend(loc=\"upper right\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q3hdQxcp6zqw","colab_type":"code","colab":{}},"source":["idx_test_img = 4717 #@param {type:\"slider\", min:0, max:9999, step:1}\n","\n","img_test = MNIST.x_test_noise[idx_test_img:idx_test_img+5]\n","\n","img_recon = autoencoder(img_test)\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(np.hstack(np.squeeze(MNIST.x_test[idx_test_img:idx_test_img+5])),'gray')\n","plt.title(\"Original\", fontsize=15)\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(np.hstack(np.squeeze(img_test)),'gray')\n","plt.title(\"Noise images\", fontsize=15)\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(np.hstack(np.squeeze(img_recon)),'gray')\n","plt.title(\"Reconstructed\", fontsize=15)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QhcFHqOZlWNC","colab":{}},"source":["#autoencoder.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate))\n","\n","# train the convolutional autoencoder\n","#H = autoencoder.fit(MNIST.train_dataset.batch(batch_size),\n","#                    validation_data=MNIST.test_dataset.batch(batch_size),\n","#\t\t\t\t\t\t\t\t\t\tepochs=num_epochs)\n","\n","#N = np.arange(0, num_epochs)\n","#plt.style.use(\"ggplot\")\n","#plt.figure()\n","#plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","#plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","#plt.title(\"Training Loss and Accuracy\")\n","#plt.xlabel(\"Epoch #\")\n","#plt.ylabel(\"Loss/Accuracy\")\n","#plt.legend(loc=\"lower left\")"],"execution_count":0,"outputs":[]}]}